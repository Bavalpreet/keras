{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data preparation and processing"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from random import randint\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import MinMaxScaler","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = []\ntrain_samples = []","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As motivation for this data, let’s suppose that an experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial. The trial had 2100 participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n\nThe trial showed that around 95% of patients 65 or older experienced side effects from the drug, and around 95% of patients under 65 experienced no side effects, generally showing that elderly individuals were more likely to experience side effects.\n\nUltimately, we want to build a model to tell us whether or not a patient will experience side effects solely based on the patient's age. The judgement of the model will be based on the training data.\n\nNote that with the simplicity of the data along with the conclusions drawn from it, a neural network may be overkill, but understand this is just to first get introduced to working with data for deep learning, and later, we'll be making use of more advanced data sets.\n\nThe block of code below shows how to generate this dummy data."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(50):\n    # The ~5% of younger individuals who did experience side effects\n    random_younger = randint(13,64)\n    train_samples.append(random_younger)\n    train_labels.append(1)\n#     print(train_samples)\n\n    # The ~5% of older individuals who did not experience side effects\n    random_older = randint(65,100)\n    train_samples.append(random_older)\n    train_labels.append(0)\n\nfor i in range(1000):\n    # The ~95% of younger individuals who did not experience side effects\n    random_younger = randint(13,64)\n    train_samples.append(random_younger)\n    train_labels.append(0)\n\n    # The ~95% of older individuals who did experience side effects\n    random_older = randint(65,100)\n    train_samples.append(random_older)\n    train_labels.append(1)","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data Processing\n\nWe now convert both lists into numpy arrays due to what we discussed the fit() function expects, and we then shuffle the arrays to remove any order that was imposed on the data during the creation process."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = np.array(train_labels)\ntrain_samples = np.array(train_samples)\ntrain_labels, train_samples = shuffle(train_labels, train_samples)","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this form, we now have the ability to pass the data to the model because it is now in the required format, however, before doing that, we'll first scale the data down to a range from 0 to 1.\n\nWe'll use scikit-learn’s MinMaxScaler class to scale all of the data down from a scale ranging from 13 to 100 to be on a scale from 0 to 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler(feature_range=(0,1))\nscaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We reshape the data as a technical requirement just since the fit_transform() function doesn’t accept 1D data by default."},{"metadata":{"trusted":true},"cell_type":"code","source":"type(scaled_train_samples)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"numpy.ndarray"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_train_samples.shape","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"(2100, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.shape","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"(2100,)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"##### Create An Artificial Neural Network With TensorFlow's Keras API"},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dense\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_crossentropy","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Build a Sequential Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# or you can do like this -->  model.add(l4)\n# so i prefer to do it like this --> model = sequential([l1,l2,l3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential([\n    Dense(units=16, input_shape=(1,), activation='relu'),\n    Dense(units=32, activation='relu'),\n    Dense(units=2, activation='softmax')\n])","execution_count":27,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"model is an instance of a Sequential object. A tf.keras.Sequential model is a linear stack of layers. It accepts a list, and each element in the list should be a layer.\n\nAs you can see, we have passed a list of layers to the Sequential constructor. Let's go through each of the layers in this list now.\n"},{"metadata":{},"cell_type":"markdown","source":">  Note, if you don’t explicitly set an activation function, then Keras will use the linear activation function."},{"metadata":{},"cell_type":"markdown","source":"*First Hidden Layer*\nOur first layer is a Dense layer. This type of layer is our standard fully-connected or densely-connected neural network layer. The first required parameter that the Dense layer expects is the number of neurons or units the layer has, and we’re arbitrarily setting this to 16.\n\nAdditionally, the model needs to know the shape of the input data. For this reason, we specify the shape of the input data in the first hidden layer in the model (and only this layer). The parameter called input_shape is how we specify this.\n\nAs discussed, we’ll be training our network on the data that we generated and processed in the previous episode, and recall, this data is one-dimensional. The input_shape parameter expects a tuple of integers that matches the shape of the input data, so we correspondingly specify (1,) as the input_shape of our one-dimensional data.\n\nYou can think of the way we specify the input_shape here as acting as an implicit input layer. The input layer of a neural network is the underlying raw data itself, therefore we don't create an explicit input layer. This first Dense layer that we're working with now is actually the first hidden layer.\n\nLastly, an optional parameter that we’ll set for the Dense layer is the activation function to use after this layer. We’ll use the popular choice of relu."},{"metadata":{},"cell_type":"markdown","source":"2nd  hidden layer also the same as the above menioned\n*Output Layer*\nLastly, we specify the output layer. This layer is also a Dense layer, and it will have 2 neurons. This is because we have two possible outputs: either a patient experienced side effects, or the patient did not experience side effects.\n\nThis time, the activation function we’ll use is softmax, which will give us a probability distribution among the possible outputs."},{"metadata":{},"cell_type":"markdown","source":"*Note that we can call summary() on our model to get a quick visualization of it.*"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":28,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 16)                32        \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                544       \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 66        \n=================================================================\nTotal params: 642\nTrainable params: 642\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"##### Train An Artificial Neural Network With TensorFlow's Keras API"},{"metadata":{},"cell_type":"markdown","source":"Compiling The Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":29,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This function configures the model for training and expects a number of parameters. First, we specify the optimizer Adam. Adam accepts an optional parameter learning_rate, which we’ll set to 0.0001.\n\nThe next parameter we specify is loss. We’ll be using sparse_categorical_crossentropy, given that our labels are in integer format.\n\nNote that when we have only two classes, we could instead configure our output layer to have only one output, rather than two, and use binary_crossentropy as our loss, rather than categorical_crossentropy. Both options work equally well and achieve the exact same result.\n\nWith binary_crossentropy, however, the last layer would need to use sigmoid, rather than softmax, as its activation function.\n\nMoving on, the last parameter we specify in compile() is metrics. This parameter expects a list of metrics that we’d like to be evaluated by the model during training and testing. We’ll set this to a list that contains the string ‘accuracy’."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2)","execution_count":34,"outputs":[{"output_type":"stream","text":"Epoch 1/30\n210/210 - 0s - loss: 0.2381 - accuracy: 0.9500\nEpoch 2/30\n210/210 - 0s - loss: 0.2377 - accuracy: 0.9471\nEpoch 3/30\n210/210 - 0s - loss: 0.2377 - accuracy: 0.9519\nEpoch 4/30\n210/210 - 0s - loss: 0.2377 - accuracy: 0.9481\nEpoch 5/30\n210/210 - 0s - loss: 0.2375 - accuracy: 0.9481\nEpoch 6/30\n210/210 - 0s - loss: 0.2374 - accuracy: 0.9524\nEpoch 7/30\n210/210 - 0s - loss: 0.2372 - accuracy: 0.9490\nEpoch 8/30\n210/210 - 0s - loss: 0.2370 - accuracy: 0.9467\nEpoch 9/30\n210/210 - 0s - loss: 0.2370 - accuracy: 0.9510\nEpoch 10/30\n210/210 - 0s - loss: 0.2368 - accuracy: 0.9514\nEpoch 11/30\n210/210 - 0s - loss: 0.2368 - accuracy: 0.9505\nEpoch 12/30\n210/210 - 0s - loss: 0.2365 - accuracy: 0.9514\nEpoch 13/30\n210/210 - 0s - loss: 0.2367 - accuracy: 0.9462\nEpoch 14/30\n210/210 - 0s - loss: 0.2362 - accuracy: 0.9514\nEpoch 15/30\n210/210 - 0s - loss: 0.2364 - accuracy: 0.9500\nEpoch 16/30\n210/210 - 0s - loss: 0.2360 - accuracy: 0.9524\nEpoch 17/30\n210/210 - 0s - loss: 0.2360 - accuracy: 0.9524\nEpoch 18/30\n210/210 - 0s - loss: 0.2360 - accuracy: 0.9510\nEpoch 19/30\n210/210 - 0s - loss: 0.2356 - accuracy: 0.9486\nEpoch 20/30\n210/210 - 0s - loss: 0.2355 - accuracy: 0.9505\nEpoch 21/30\n210/210 - 0s - loss: 0.2355 - accuracy: 0.9524\nEpoch 22/30\n210/210 - 0s - loss: 0.2354 - accuracy: 0.9524\nEpoch 23/30\n210/210 - 0s - loss: 0.2353 - accuracy: 0.9514\nEpoch 24/30\n210/210 - 0s - loss: 0.2353 - accuracy: 0.9495\nEpoch 25/30\n210/210 - 0s - loss: 0.2350 - accuracy: 0.9524\nEpoch 26/30\n210/210 - 0s - loss: 0.2351 - accuracy: 0.9510\nEpoch 27/30\n210/210 - 0s - loss: 0.2348 - accuracy: 0.9510\nEpoch 28/30\n210/210 - 0s - loss: 0.2347 - accuracy: 0.9510\nEpoch 29/30\n210/210 - 0s - loss: 0.2346 - accuracy: 0.9495\nEpoch 30/30\n210/210 - 0s - loss: 0.2346 - accuracy: 0.9524\n","name":"stdout"},{"output_type":"execute_result","execution_count":34,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fdc3c463b90>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"we specify verbose=2. This just specifies how much output to the console we want to see during each epoch of training. The verbosity levels range from 0 to 2, so we’re getting the most verbose output.\n\nWhen we call fit() on the model, the model trains, and we get this output."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}